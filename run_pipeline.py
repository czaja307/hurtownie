"""
INSTRUKCJA URUCHOMIENIA HURTOWNI DANYCH OLIST
=============================================

KROK 1: Przygotowanie Å›rodowiska
---------------------------------
1. Upewnij siÄ™, Å¼e masz zainstalowane biblioteki Python:
   pip install pandas numpy pyodbc

2. SprawdÅº poÅ‚Ä…czenie z SQL Server (192.168.1.204)
   - UÅ¼ytkownik: sa
   - HasÅ‚o: password
   - Baza danych zostanie utworzona automatycznie: OlistDW

KROK 2: Uruchomienie procesu ETL
---------------------------------
python create_data_warehouse.py

Ten skrypt wykona nastÄ™pujÄ…ce operacje:
âœ“ Wczyta dane z plikÃ³w CSV (data/olist/ i data/cities/)
âœ“ Utworzy schemat hurtowni danych (tabele wymiarÃ³w i faktÃ³w)
âœ“ WypeÅ‚ni wymiary danymi z transformacjÄ… i wzbogaceniem
âœ“ Utworzy tabelÄ™ faktÃ³w z >10,000 rekordÃ³w
âœ“ Wygeneruje widoki z miarami kalkulowanymi
âœ“ Zapisze przykÅ‚adowe zapytania OLAP

KROK 3: Dodatkowe analizy
-------------------------
python olap_cube_definition.py

Wygeneruje zaawansowane zapytania analityczne.

STRUKTURA HURTOWNI:
==================

WYMIARY (5):
- DIM_Time (hierarchiczny: Rok â†’ KwartaÅ‚ â†’ MiesiÄ…c â†’ DzieÅ„)
- DIM_Customer (hierarchiczny: Region â†’ Stan â†’ Miasto â†’ Klient + dane ekonomiczne)
- DIM_Seller (hierarchiczny: Region â†’ Stan â†’ Miasto â†’ Sprzedawca + dane ekonomiczne)  
- DIM_Payment (typy pÅ‚atnoÅ›ci, raty, kategorie)
- DIM_Review (oceny, satysfakcja)

FAKTY:
- FACT_Orders (zamÃ³wienia z miarami)

MIARY:
- Addytywne: Order_Value, Freight_Value, Items_Count
- Nieaddytywne: Delivery_Days (Å›rednia), Review_Score (Å›rednia)
- Kalkulowane: Total_Revenue, Revenue_Per_Customer, Freight_Percentage

PLIKI WYJÅšCIOWE:
===============
- sample_olap_queries.sql - podstawowe zapytania OLAP
- advanced_olap_analysis.sql - zaawansowane analizy wielowymiarowe

PRZYKÅADOWE ANALIZY:
===================
1. SprzedaÅ¼ w czasie (roll-up/drill-down)
2. Analiza geograficzna z PKB i HDI miast
3. Segmentacja klientÃ³w RFM
4. Korelacje ekonomiczne
5. Analizy sezonowoÅ›ci
6. EfektywnoÅ›Ä‡ dostaw vs satysfakcja
7. Trendy rok-do-roku
8. Cross-dimensional analysis
"""

import subprocess
import sys
import os

def install_requirements():
    """Instalacja wymaganych bibliotek"""
    print("ğŸ“¦ Instalowanie wymaganych bibliotek...")
    
    packages = ['pandas', 'numpy', 'pyodbc']
    
    for package in packages:
        try:
            __import__(package)
            print(f"  âœ“ {package} juÅ¼ zainstalowany")
        except ImportError:
            print(f"  ğŸ“¥ Instalowanie {package}...")
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])

def check_data_files():
    """Sprawdzenie dostÄ™pnoÅ›ci plikÃ³w danych"""
    print("ğŸ“ Sprawdzanie plikÃ³w danych...")
    
    data_path = r'c:\Users\Kuba\PycharmProjects\hurtownie\data'
    
    required_files = [
        'olist/olist_orders_dataset.csv',
        'olist/olist_order_items_dataset.csv', 
        'olist/olist_customers_dataset.csv',
        'olist/olist_sellers_dataset.csv',
        'olist/olist_order_payments_dataset.csv',
        'olist/olist_order_reviews_dataset.csv',
        'cities/BRAZIL_CITIES_REV2022.CSV'
    ]
    
    missing_files = []
    
    for file_path in required_files:
        full_path = os.path.join(data_path, file_path)
        if os.path.exists(full_path):
            print(f"  âœ“ {file_path}")
        else:
            print(f"  âœ— {file_path} - BRAK PLIKU")
            missing_files.append(file_path)
    
    if missing_files:
        print(f"\nâŒ Brakuje {len(missing_files)} plikÃ³w danych!")
        return False
    
    print("  âœ“ Wszystkie pliki danych dostÄ™pne")
    return True

def run_etl_pipeline():
    """Uruchomienie peÅ‚nego pipeline ETL"""
    print("ğŸš€ URUCHAMIANIE PIPELINE HURTOWNI DANYCH OLIST")
    print("=" * 60)
    
    # Krok 1: Sprawdzenie wymagaÅ„
    if not check_data_files():
        print("âŒ Zatrzymano - brakuje plikÃ³w danych")
        return False
    
    # Krok 2: Instalacja bibliotek
    try:
        install_requirements()
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d instalacji bibliotek: {e}")
        return False
    
    # Krok 3: Import i uruchomienie ETL
    try:
        print("\nğŸ”§ Uruchamianie gÅ‚Ã³wnego procesu ETL...")
        from create_data_warehouse import OlistDataWarehouse
        
        dw = OlistDataWarehouse()
        success = dw.run_etl_process()
        
        if success:
            print("\nğŸ¯ Generowanie dodatkowych analiz...")
            from olap_cube_definition import save_advanced_queries
            save_advanced_queries()
            
            print("\n" + "=" * 60)
            print("ğŸ‰ PIPELINE ZAKOÅƒCZONY POMYÅšLNIE!")
            print("\nğŸ“Š NASTÄ˜PNE KROKI:")
            print("   1. PoÅ‚Ä…cz siÄ™ z bazÄ… OlistDW na SQL Server")
            print("   2. Uruchom zapytania z sample_olap_queries.sql")  
            print("   3. Eksploruj zaawansowane analizy z advanced_olap_analysis.sql")
            print("   4. UtwÃ³rz raporty w Power BI/Tableau")
            
            return True
        else:
            print("âŒ ETL zakoÅ„czony bÅ‚Ä™dem")
            return False
            
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d podczas ETL: {e}")
        return False

if __name__ == "__main__":
    run_etl_pipeline()
